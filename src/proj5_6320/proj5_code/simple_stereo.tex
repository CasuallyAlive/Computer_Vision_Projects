% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\KOMAoption{captions}{tableheading}
\makeatletter
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Project 5: Depth Estimation using Stereo},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Project 5: Depth Estimation using Stereo}
\author{}
\date{}

\begin{document}
\maketitle
\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[boxrule=0pt, sharp corners, frame hidden, interior hidden, enhanced, borderline west={3pt}{0pt}{shadecolor}, breakable]}{\end{tcolorbox}}\fi

\hypertarget{part-1-simple-stereo-by-matching-patches}{%
\subsection{Part 1: Simple stereo by matching
patches}\label{part-1-simple-stereo-by-matching-patches}}

We know that there is some encoding of depth when the images are
captured using a stereo rig, much like human eyes.

You can try a simple experiment to see the stereo effect in action. Try
seeing a scene with only your left eye. Then close your left eye and see
using your right eye. Make the transition quickly. You should notice a
horizontal shift in the image perceived. Can you comment on the
difference in shift for different objects when you do this experiment?
Is it related to the depth of the objects in some way?

In this notebook, we will generate disparity maps, which is the map of
horizontal shifts estimated at each pixel. We will start working on a
simple algorithm which will then be evolved to give better disparity
maps.

\hypertarget{setup}{%
\subsection{Setup}\label{setup}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Install Miniconda. It doesn't matter whether you use Python 2 or 3
  because we will create our own environment that uses 3 anyways.
\item
  Create a conda environment using the appropriate command. On Windows,
  open the installed ``Conda prompt'' to run the command. On MacOS and
  Linux, you can just use a terminal window to run the command, Modify
  the command based on your OS (linux, mac, or win):
  \texttt{conda\ env\ create\ -f\ proj5\_env\_\textless{}OS\textgreater{}.yml}
\item
  This should create an environment named `proj5'. Activate it using the
  Windows command, activate proj5 or the MacOS / Linux command, source
  activate proj5
\item
  Install the project package, by running \texttt{pip\ install\ -e\ .}
  inside the repo folder.
\item
  Run the notebook using
  \texttt{jupyter\ notebook\ ./proj5\_code/simple\_stereo.ipynb}
\item
  Ensure that all sanity checks are passing by running pytest inside the
  ``unit\_tests/'' folder.
\item
  Generate the zip folder for the code portion of your submission once
  you've finished the project using
  \texttt{python\ zip\_submission.py\ -\/-username\ \textless{}your\_uid\textgreater{}}
  and submit to Canvas.
\end{enumerate}

\hypertarget{writeup}{%
\subsection{Writeup}\label{writeup}}

For this project, you must do a project report using the template slides
provided to you. Do not change the order of the slides or remove any
slides, as this will affect the grading process on Gradescope and you
will be deducted points. In the report you will describe your algorithm
and any decisions you made to write your algorithm a particular way.
Then you will show and discuss the results of your algorithm. The
template slides provide guidance for what you should include in your
report. A good writeup doesn't just show results--it tries to draw some
conclusions from the experiments. You must convert the slide deck into a
PDF for your submission.

If you choose to do anything extra, add slides after the slides given in
the template deck to describe your implementation, results, and
analysis. Adding slides in between the report template will cause issues
with Gradescope, and you will be deducted points. You will not receive
full credit for your extra credit implementations if they are not
described adequately in your writeup.

\hypertarget{rubric-total-100-pts}{%
\subsection{Rubric (Total : 100 pts)}\label{rubric-total-100-pts}}

\begin{itemize}
\tightlist
\item
  60 pts: Code

  \begin{itemize}
  \tightlist
  \item
    15 pts: generate\_random\_stereogram in utils.py
  \item
    15 pts: similarity\_measures.py
  \item
    30 pts: disparity\_map.py
  \end{itemize}
\item
  40 pts: Report
\item
  -5*n pts: Lose 5 points for every time you do not follow the
  instructions for the hand-in format.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ sys}
\NormalTok{sys.path.append(}\StringTok{\textquotesingle{}..\textquotesingle{}}\NormalTok{)}

\ImportTok{from}\NormalTok{ proj5\_code.utils }\ImportTok{import}\NormalTok{ load\_image, PIL\_resize, generate\_random\_stereogram, stereo\_helper\_fn}
\ImportTok{from}\NormalTok{ proj5\_code.disparity\_map }\ImportTok{import}\NormalTok{ calculate\_disparity\_map}
\ImportTok{from}\NormalTok{ proj5\_code.similarity\_measures }\ImportTok{import}\NormalTok{ ssd\_similarity\_measure, sad\_similarity\_measure}

\ImportTok{import}\NormalTok{ torch}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}

\ImportTok{from}\NormalTok{ unit\_tests.test\_base }\ImportTok{import}\NormalTok{ verify}

\OperatorTok{\%}\NormalTok{load\_ext autoreload}
\OperatorTok{\%}\NormalTok{autoreload }\DecValTok{2}
\end{Highlighting}
\end{Shaded}

We will use a helper function called stereo\_helper\_fn for utils.py for
calculating and plotting the disparity maps using the functions defined
by you

\hypertarget{random-dot-stereogram}{%
\subsection{Random dot stereogram}\label{random-dot-stereogram}}

It was once believed that in order to perceive depth, one must either
match feature points (like SIFT) between left and right images, or rely
upon cues such as shadows.

A random dot stereogram eliminates all other depth cues and hence it
proves that a stereo setup is sufficient to get an idea of the depth of
the scene.

A random dot stereogram is generated by the follow steps: 1. Create the
left image with random dots at each pixel (0/1 values). 2. Create the
right image as the copy of left image. 3. Select a region in the right
image and shift it horizontally. 4. Add a random pattern in the right
image in the empty region created after the shift.

You will implement these steps in the function
\texttt{generate\_random\_stereogram()} in \texttt{utils.py}. A
corresponding unit test is defined in test\_utils.py.

Please read the documentation carefully.

\hypertarget{reflection-question}{%
\paragraph{Reflection Question:}\label{reflection-question}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  What do you think of the random dot stereogram? Can you judge the
  depth by looking at the images?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#generate left and right images}
\NormalTok{im\_left, im\_right }\OperatorTok{=}\NormalTok{ generate\_random\_stereogram(im\_size}\OperatorTok{=}\NormalTok{(}\DecValTok{51}\NormalTok{, }\DecValTok{51}\NormalTok{, }\DecValTok{3}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ unit\_tests.test\_utils }\ImportTok{import}\NormalTok{ test\_generate\_random\_stereogram}

\BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}Test for random dot stereogram\textquotesingle{}}\NormalTok{, verify(test\_generate\_random\_stereogram))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Test for random dot stereogram "Correct"
\end{verbatim}

\hypertarget{similarity-measure}{%
\subsection{Similarity measure}\label{similarity-measure}}

We will use a similarity function to compare patches between left and
right images. We will implement two similarity functions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sum of squared differences (SSD):
  \(SSD\left(A,B\right) = \sum_{i,j}\left(A_{ij} - B_{ij}\right)^2\)
\item
  Sum of absolute differences (SAD):
  \(SAD\left(A,B\right) = \sum_{i,j}|A_{ij} - B_{ij}|\)
\end{enumerate}

You will implement these functions in \texttt{similarity\_measures.py}.
The corresponding unit tests are defined in
\texttt{test\_similarity\_measures.py}.

Implement the similarity function and disparity map calculation. You
will need it in the next steps

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ unit\_tests.test\_similarity\_measures }\ImportTok{import}\NormalTok{ (}
\NormalTok{  test\_ssd\_similarity\_measure\_values, }
\NormalTok{  test\_sad\_similarity\_measure\_values, }
\NormalTok{  test\_similarity\_measure\_size\_compatibility}
\NormalTok{)}

\BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}Testing value for SAD measure\textquotesingle{}}\NormalTok{, verify(test\_sad\_similarity\_measure\_values))}
\BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}Testing value for SSD measure\textquotesingle{}}\NormalTok{, verify(test\_ssd\_similarity\_measure\_values))}
\BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}Testing input size compatibility for measures\textquotesingle{}}\NormalTok{, verify(test\_similarity\_measure\_size\_compatibility))}

  
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Testing value for SAD measure "Correct"
Testing value for SSD measure "Correct"
Testing input size compatibility for measures "Correct"
\end{verbatim}

\hypertarget{disparity-map}{%
\subsection{Disparity Map}\label{disparity-map}}

We are now ready to write the code for a simple algorithm for stereo
matching.

Example of a stereo algorithm

These are the steps taken in this image (and will be implemented by
you):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Pick a patch in the left image (red block), P1.
\item
  Place the patch in the same (x,y) coordinates in the right image (red
  block). As this is binocular stereo, we will need to search for P1 on
  the left side starting from this position. Make sure you understand
  this point well before proceeding further.
\item
  Slide the block of candidates to the left (indicated by the different
  pink blocks). The search area is restricted by the parameter
  max\_search\_bound in the code. The candidates will overlap.
\item
  We will pick the candidate patch with the minimum similarity error
  (green block). The horizontal shift from the red block to the green
  block in this image is the disparity value for the centre of P1 in the
  left image.
\end{enumerate}

Note: the images have already been rectified and hence we can search on
just a horizontal scan line.

The function works as follows:

\begin{itemize}
\tightlist
\item
  Input

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    Left image
  \item
    Right image
  \item
    Similarity function
  \item
    Patch size
  \item
    Max search value
  \end{enumerate}
\item
  Output

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    Disparity map
  \end{enumerate}
\end{itemize}

Implement this in \texttt{disparity\_map.py} (please read the
documentation carefully!). The corresponding unit tests are defined in
\texttt{test\_disparity\_map.py}.

\textbf{Deliverables}: All the disparity maps + Observations and
Analysis:

\hypertarget{reflection-question-1}{%
\paragraph{Reflection Question}\label{reflection-question-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  What is the effect of increasing the block size?
\item
  Why is the result poor on the left edge and not on the other edges?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ unit\_tests.test\_disparity\_map }\ImportTok{import}\NormalTok{ (}
\NormalTok{  test\_disparity\_deltafn\_failure,}
\NormalTok{  test\_disparity\_deltafn\_success,}
\NormalTok{  test\_disparity\_map\_size,}
\NormalTok{  test\_disparity\_random\_stereogram,}
\NormalTok{  test\_disparity\_translation\_shift}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}Testing for disparity map on a delta function\textquotesingle{}}\NormalTok{, verify(test\_disparity\_deltafn\_failure))}
\BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}Testing for disparity map on a delta function\textquotesingle{}}\NormalTok{, verify(test\_disparity\_deltafn\_success))}
\BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}Testing disparity map size\textquotesingle{}}\NormalTok{, verify(test\_disparity\_map\_size))}
\BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}Testing random stereogram ouptut\textquotesingle{}}\NormalTok{, verify(test\_disparity\_random\_stereogram))}
\BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}Testing disparity on translation shift\textquotesingle{}}\NormalTok{, verify(test\_disparity\_translation\_shift))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Testing for disparity map on a delta function "Wrong"
Testing for disparity map on a delta function "Wrong"
Testing disparity map size "Wrong"
Testing random stereogram ouptut "Wrong"
Testing disparity on translation shift "Wrong"
\end{verbatim}

Response: 1 - Increasing block size leads to faster computation but
results are generally less accurate. 2 - Pixels on left edge may lack
corresponding pixels in the right image; therefore, leading to
incomplete information for disparity calculation.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stereo\_helper\_fn(im\_left, im\_right, block\_size }\OperatorTok{=}\NormalTok{ [}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{9}\NormalTok{,}\DecValTok{13}\NormalTok{], max\_search\_bound}\OperatorTok{=}\DecValTok{8}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{simple_stereo_files/figure-pdf/cell-8-output-1.png}

}

\end{figure}

\begin{verbatim}
AssertionError: 
\end{verbatim}

\begin{figure}[H]

{\centering \includegraphics{simple_stereo_files/figure-pdf/cell-8-output-3.png}

}

\end{figure}

\hypertarget{error-profile-analysis}{%
\subsection{Error profile analysis}\label{error-profile-analysis}}

In the error profile analysis, you have to find two examples which
display convex and non-convex error profile respectively. For reference,
these are the plots we obtained:

Convex Profile

Non-Convex Profile

Before computing the full disparity map, we will analyse the similarity
error between patches. You will have to find out different patches in
the image which exhibit a close-to-convex error profile, and a highly
non-convex profile.

\textbf{Deliverable}: Find the patch in the left image and search space
in the right image, and the similarity error plot for the two cases, and
copy it to the report

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Load the image}
\NormalTok{base\_path }\OperatorTok{=} \StringTok{\textquotesingle{}../data/adirondack/\textquotesingle{}}
\NormalTok{im\_left }\OperatorTok{=}\NormalTok{ PIL\_resize(load\_image(base\_path }\OperatorTok{+} \StringTok{\textquotesingle{}im\_left.png\textquotesingle{}}\NormalTok{), (}\FloatTok{0.1}\NormalTok{, }\FloatTok{0.1}\NormalTok{))}
\NormalTok{im\_right }\OperatorTok{=}\NormalTok{ PIL\_resize(load\_image(base\_path }\OperatorTok{+} \StringTok{\textquotesingle{}im\_right.png\textquotesingle{}}\NormalTok{), (}\FloatTok{0.1}\NormalTok{, }\FloatTok{0.1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fig, (ax1, ax2) }\OperatorTok{=}\NormalTok{ plt.subplots(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{, figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{10}\NormalTok{))}

\NormalTok{ax1.imshow(im\_left, interpolation}\OperatorTok{=}\VariableTok{None}\NormalTok{)}
\NormalTok{ax1.title.set\_text(}\StringTok{\textquotesingle{}Left image\textquotesingle{}}\NormalTok{)}
\NormalTok{ax1.autoscale(}\VariableTok{False}\NormalTok{)}
\NormalTok{ax1.set\_axis\_on()}

\NormalTok{ax2.imshow(im\_right, interpolation}\OperatorTok{=}\VariableTok{None}\NormalTok{)}
\NormalTok{ax2.title.set\_text(}\StringTok{\textquotesingle{}Right image\textquotesingle{}}\NormalTok{)}
\NormalTok{ax2.autoscale(}\VariableTok{False}\NormalTok{)}
\NormalTok{ax2.set\_axis\_on()}

\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\hypertarget{convex-error-profile}{%
\subsection{Convex error profile}\label{convex-error-profile}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# extract a patch of interest from the left image}
\NormalTok{patch\_size}\OperatorTok{=}\DecValTok{15}
\NormalTok{x\_idx, y\_idx }\OperatorTok{=}\NormalTok{ (}\VariableTok{None}\NormalTok{, }\VariableTok{None}\NormalTok{) }\CommentTok{\# }\AlertTok{TODO}\CommentTok{: replace with integers}
\NormalTok{patch\_left\_img }\OperatorTok{=}\NormalTok{ torch.tensor(im\_left[x\_idx:x\_idx}\OperatorTok{+}\NormalTok{patch\_size}\OperatorTok{+}\DecValTok{1}\NormalTok{, y\_idx:y\_idx}\OperatorTok{+}\NormalTok{patch\_size}\OperatorTok{+}\DecValTok{1}\NormalTok{,:])}
\NormalTok{plt.imshow(patch\_left\_img)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# get the search area in the right image}
\NormalTok{max\_search\_bound }\OperatorTok{=} \DecValTok{0} \CommentTok{\# might need adjustment based on your (x\_idx, y\_idx)}
\NormalTok{search\_area\_right\_img }\OperatorTok{=}\NormalTok{ torch.tensor(}
\NormalTok{  im\_right[x\_idx:x\_idx}\OperatorTok{+}\NormalTok{patch\_size}\OperatorTok{+}\DecValTok{1}\NormalTok{, y\_idx}\OperatorTok{{-}}\NormalTok{max\_search\_bound:y\_idx}\OperatorTok{+}\NormalTok{patch\_size}\OperatorTok{+}\DecValTok{1}\NormalTok{,:]}
\NormalTok{)}
\NormalTok{plt.imshow(search\_area\_right\_img)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{similarity\_vals }\OperatorTok{=}\NormalTok{ np.array(}
\NormalTok{  [sad\_similarity\_measure(patch\_left\_img, search\_area\_right\_img[:,h\_idx:h\_idx}\OperatorTok{+}\NormalTok{patch\_size}\OperatorTok{+}\DecValTok{1}\NormalTok{,:]) }
   \ControlFlowTok{for}\NormalTok{ h\_idx }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(search\_area\_right\_img.shape[}\DecValTok{1}\NormalTok{]}\OperatorTok{{-}}\NormalTok{patch\_size}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)}
\NormalTok{  ])}
\NormalTok{plt.plot(similarity\_vals)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\hypertarget{non-convex-error-profile}{%
\subsection{Non-Convex error profile}\label{non-convex-error-profile}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# extract a patch of interest from the left image}
\NormalTok{patch\_size}\OperatorTok{=}\DecValTok{15}
\NormalTok{x\_idx, y\_idx }\OperatorTok{=}\NormalTok{ (}\VariableTok{None}\NormalTok{, }\VariableTok{None}\NormalTok{) }\CommentTok{\# }\AlertTok{TODO}\CommentTok{: replace with integers}
\NormalTok{patch\_left\_img }\OperatorTok{=}\NormalTok{ torch.tensor(im\_left[x\_idx:x\_idx}\OperatorTok{+}\NormalTok{patch\_size}\OperatorTok{+}\DecValTok{1}\NormalTok{, y\_idx:y\_idx}\OperatorTok{+}\NormalTok{patch\_size}\OperatorTok{+}\DecValTok{1}\NormalTok{,:])}
\NormalTok{plt.imshow(patch\_left\_img)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# get the search area in the right image}
\NormalTok{max\_search\_bound }\OperatorTok{=} \DecValTok{0} \CommentTok{\# might need adjustment based on your (x\_idx, y\_idx)}
\NormalTok{search\_area\_right\_img }\OperatorTok{=}\NormalTok{ torch.tensor(}
\NormalTok{  im\_right[x\_idx:x\_idx}\OperatorTok{+}\NormalTok{patch\_size}\OperatorTok{+}\DecValTok{1}\NormalTok{, y\_idx}\OperatorTok{{-}}\NormalTok{max\_search\_bound:y\_idx}\OperatorTok{+}\NormalTok{patch\_size}\OperatorTok{+}\DecValTok{1}\NormalTok{,:]}
\NormalTok{)}
\NormalTok{plt.imshow(search\_area\_right\_img)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{similarity\_vals }\OperatorTok{=}\NormalTok{ np.array(}
\NormalTok{  [sad\_similarity\_measure(patch\_left\_img, search\_area\_right\_img[:,h\_idx:h\_idx}\OperatorTok{+}\NormalTok{patch\_size}\OperatorTok{+}\DecValTok{1}\NormalTok{,:]) }
   \ControlFlowTok{for}\NormalTok{ h\_idx }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(search\_area\_right\_img.shape[}\DecValTok{1}\NormalTok{]}\OperatorTok{{-}}\NormalTok{patch\_size}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)}
\NormalTok{  ])}
\NormalTok{plt.plot(similarity\_vals)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\hypertarget{real-life-stereo-images}{%
\section{Real life stereo images}\label{real-life-stereo-images}}

\hypertarget{example-1}{%
\subsection{Example 1}\label{example-1}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stereo\_helper\_fn(torch.tensor(im\_left), torch.tensor(im\_right), max\_search\_bound}\OperatorTok{=}\DecValTok{25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\textbf{Deliverables} 1. Copy the disparity map for the patch size you
feel works the best 2. Can you think of an explanation as to why the
back rest of the chair appears \emph{blocky}?

Tip: you can see all the examples and deliverables before answering.
This will help you understand the core ideas being asked.

\hypertarget{set-2}{%
\subsection{Set 2}\label{set-2}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{base\_path }\OperatorTok{=} \StringTok{\textquotesingle{}../data/bicycle/\textquotesingle{}}
\NormalTok{im\_left }\OperatorTok{=}\NormalTok{ PIL\_resize(load\_image(base\_path }\OperatorTok{+} \StringTok{\textquotesingle{}im\_left.png\textquotesingle{}}\NormalTok{), (}\FloatTok{0.1}\NormalTok{, }\FloatTok{0.1}\NormalTok{))}
\NormalTok{im\_right }\OperatorTok{=}\NormalTok{ PIL\_resize(load\_image(base\_path }\OperatorTok{+} \StringTok{\textquotesingle{}im\_right.png\textquotesingle{}}\NormalTok{), (}\FloatTok{0.1}\NormalTok{, }\FloatTok{0.1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stereo\_helper\_fn(torch.tensor(im\_left), torch.tensor(im\_right), block\_size}\OperatorTok{=}\NormalTok{[}\DecValTok{11}\NormalTok{], max\_search\_bound}\OperatorTok{=}\DecValTok{20}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{set-3}{%
\subsection{Set 3}\label{set-3}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{base\_path }\OperatorTok{=} \StringTok{\textquotesingle{}../data/bowling/\textquotesingle{}}
\NormalTok{im\_left }\OperatorTok{=}\NormalTok{ PIL\_resize(load\_image(base\_path }\OperatorTok{+} \StringTok{\textquotesingle{}im\_left.png\textquotesingle{}}\NormalTok{), (}\FloatTok{0.2}\NormalTok{, }\FloatTok{0.2}\NormalTok{))}
\NormalTok{im\_right }\OperatorTok{=}\NormalTok{ PIL\_resize(load\_image(base\_path }\OperatorTok{+} \StringTok{\textquotesingle{}im\_right.png\textquotesingle{}}\NormalTok{), (}\FloatTok{0.2}\NormalTok{, }\FloatTok{0.2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stereo\_helper\_fn(torch.tensor(im\_left), torch.tensor(im\_right), block\_size}\OperatorTok{=}\NormalTok{[}\DecValTok{9}\NormalTok{], max\_search\_bound}\OperatorTok{=}\DecValTok{30}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{set-4}{%
\subsection{Set 4}\label{set-4}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{base\_path }\OperatorTok{=} \StringTok{\textquotesingle{}../data/bowling2/\textquotesingle{}}
\NormalTok{im\_left }\OperatorTok{=}\NormalTok{ PIL\_resize(load\_image(base\_path }\OperatorTok{+} \StringTok{\textquotesingle{}im\_left.png\textquotesingle{}}\NormalTok{), (}\FloatTok{0.20}\NormalTok{, }\FloatTok{0.20}\NormalTok{))}
\NormalTok{im\_right }\OperatorTok{=}\NormalTok{ PIL\_resize(load\_image(base\_path }\OperatorTok{+} \StringTok{\textquotesingle{}im\_right.png\textquotesingle{}}\NormalTok{), (}\FloatTok{0.20}\NormalTok{, }\FloatTok{0.20}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stereo\_helper\_fn(torch.tensor(im\_left), torch.tensor(im\_right), block\_size}\OperatorTok{=}\NormalTok{[}\DecValTok{9}\NormalTok{], max\_search\_bound}\OperatorTok{=}\DecValTok{30}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\textbf{Deliverables} of set 3 and set 4 combined:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Copy the disparity maps from set 4 in the report
\item
  Can you spot a peculiar behaviour of the diaprity maps near the head
  of bowling pin on the right? What do you see in the input images in
  that area? Can you figure out the reason behind this behaviour?
\item
  Notice that we have manipulated the images in set 4 to generate set 4
  images. This leads to a difference in disparity map results in the
  bottom of the image and on the green bowling ball. Can you explain why
  the disparity drops to zero in both these regions.
\end{enumerate}

\hypertarget{set-5}{%
\subsection{Set 5}\label{set-5}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{base\_path }\OperatorTok{=} \StringTok{\textquotesingle{}../data/flowers/\textquotesingle{}}
\NormalTok{im\_left }\OperatorTok{=}\NormalTok{ PIL\_resize(load\_image(base\_path }\OperatorTok{+} \StringTok{\textquotesingle{}im\_left.png\textquotesingle{}}\NormalTok{), (}\FloatTok{0.10}\NormalTok{, }\FloatTok{0.10}\NormalTok{))}
\NormalTok{im\_right }\OperatorTok{=}\NormalTok{ PIL\_resize(load\_image(base\_path }\OperatorTok{+} \StringTok{\textquotesingle{}im\_right.png\textquotesingle{}}\NormalTok{), (}\FloatTok{0.10}\NormalTok{, }\FloatTok{0.10}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stereo\_helper\_fn(torch.tensor(im\_left), torch.tensor(im\_right), block\_size}\OperatorTok{=}\NormalTok{[}\DecValTok{9}\NormalTok{], max\_search\_bound}\OperatorTok{=}\DecValTok{50}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\textbf{Observations}: (these observations do not go in the report.
These are for your understanding).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Notice the different disparity of the flower at the back and its
  shadow
\item
  Spot the zero-disparity region in the center of the house
\item
  See how smooth the disparity values are on the couch
\end{enumerate}

\hypertarget{set-6}{%
\subsection{Set 6}\label{set-6}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{base\_path }\OperatorTok{=} \StringTok{\textquotesingle{}../data/stairs/\textquotesingle{}}
\NormalTok{im\_left }\OperatorTok{=}\NormalTok{ PIL\_resize(load\_image(base\_path }\OperatorTok{+} \StringTok{\textquotesingle{}im\_left.jpg\textquotesingle{}}\NormalTok{), (}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\NormalTok{im\_right }\OperatorTok{=}\NormalTok{ PIL\_resize(load\_image(base\_path }\OperatorTok{+} \StringTok{\textquotesingle{}im\_right.jpg\textquotesingle{}}\NormalTok{), (}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stereo\_helper\_fn(torch.tensor(im\_left), torch.tensor(im\_right), block\_size }\OperatorTok{=}\NormalTok{ [}\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{7}\NormalTok{], max\_search\_bound}\OperatorTok{=}\DecValTok{15}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\textbf{Deliverables}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Why are we able to see the shift in disparity values on the wall?
\item
  What is the effect of block\_size and the ability to see stairs-like
  structure in the disparity map?
\end{enumerate}

\hypertarget{smoothing}{%
\section{Smoothing}\label{smoothing}}

One issue with the results from is that they aren't very smooth. Pixels
next to each other on the same surface can have vastly different
disparities, making the results look very noisy and patchy in some
areas. Intuitively, pixels next to each other should have a smooth
transition in disparity(unless at an object boundary or occlusion). In
this section, we try to improve our results. One way of doing this is
through the use of a smoothing constraint. The smoothing method we use
is called Semi-Global Matching(SGM) or Semi-Global Block Matching.
Before, we picked the disparity for a pixel based on the minimum
matching cost of the block using some metric(SSD or SAD). The basic idea
of SGM is to penalize pixels with a disparity that's very different than
their neighbors by adding a penalty term on top of the matching cost
term. SGM tries to minimize the global(over the entire image) energy
function \begin{equation*}
E(D) \leq \sum_{p} (C(p, D_p) + \sum_{q} PT(|D_p - D_q|))
\end{equation*} C(p,D\_p) is the matching cost for a pixel with
disparity D\_p, q is a neighboring pixel, and PT is some penalty
function penalizing the difference in disparities. You can read more
about how this method works and is optimized here:
https://elib.dlr.de/73119/1/180Hirschmueller.pdf and
https://pdfs.semanticscholar.org/bcd8/4d8bd864ff903e3fe5b91bed3f2eedacc324.pdf

Before we implement the smoothing algorithm, we need to implement a
function which computes the \textbf{cost volume}. We have already
written code to compute disparity map. We will extend that code to
compute the cost volume. Instead of taking the argmin of the similarity
error profile, we will store the tensor of error profile at each pixel
location along the third dimension.

If we have an input image of dimension (H,W,C) and max search bound of
D, the cost\_volume will be a tensor of dimension (H,W,D). The cost
volumne at (i,j) pixel is the error profile obtained for the patch in
the left image centered at (i,j).

Implement this part as function \texttt{calculate\_cost\_volume} in
\texttt{disparity\_map.py}. Feel free to reuse any code you have written
till now.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ unit\_tests.test\_disparity\_map }\ImportTok{import}\NormalTok{ (}
\NormalTok{  test\_calculate\_cost\_volume}
\NormalTok{)}

\BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}Testing for calculate\_cost\_volume\textquotesingle{}}\NormalTok{, verify(test\_calculate\_cost\_volume))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Load the image}
\ImportTok{from}\NormalTok{ semiglobalmatching.sgm }\ImportTok{import}\NormalTok{ sgm}
\ImportTok{from}\NormalTok{ scipy }\ImportTok{import}\NormalTok{ ndimage}
\ImportTok{from}\NormalTok{ proj5\_code.similarity\_measures }\ImportTok{import}\NormalTok{ sad\_similarity\_measure, ssd\_similarity\_measure}

\CommentTok{\#you can change the path to try other pairs, but you may need to fix the scaling per pair}
\NormalTok{base\_path }\OperatorTok{=} \StringTok{\textquotesingle{}../data/adirondack/\textquotesingle{}}
\NormalTok{im\_left }\OperatorTok{=}\NormalTok{ PIL\_resize(load\_image(base\_path }\OperatorTok{+} \StringTok{\textquotesingle{}im\_left.png\textquotesingle{}}\NormalTok{), (}\FloatTok{0.10}\NormalTok{, }\FloatTok{0.10}\NormalTok{))}
\NormalTok{im\_right }\OperatorTok{=}\NormalTok{ PIL\_resize(load\_image(base\_path }\OperatorTok{+} \StringTok{\textquotesingle{}im\_right.png\textquotesingle{}}\NormalTok{), (}\FloatTok{0.10}\NormalTok{, }\FloatTok{0.10}\NormalTok{))}

\CommentTok{\#calculates the disparity map with SGM, the last argument is max disparity to consider}
\NormalTok{disparity\_map }\OperatorTok{=}\NormalTok{ sgm(im\_left,im\_right, }\StringTok{"result"}\NormalTok{, }\DecValTok{30}\NormalTok{, sad\_similarity\_measure, }\DecValTok{9}\NormalTok{)}
\NormalTok{result }\OperatorTok{=}\NormalTok{ ndimage.median\_filter(disparity\_map, size}\OperatorTok{=}\DecValTok{5}\NormalTok{)}
\NormalTok{plt.figure()}
\NormalTok{plt.imshow(result, cmap}\OperatorTok{=}\StringTok{\textquotesingle{}jet\textquotesingle{}}\NormalTok{, interpolation}\OperatorTok{=}\StringTok{\textquotesingle{}nearest\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.title(}\StringTok{\textquotesingle{}Disparity map\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.colorbar()}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\textbf{Deliverables}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compare these results qualitatively to the output of the chair image
  without smoothing.
\item
  What regions of the image does smoothing seem to perform better on and
  why do you think that is?
\item
  What regions of the image does smoothing seem to perform worse on and
  why do you think that is?
\item
  Would smoothing still work for images with both a horizontal and
  vertical shift?
\end{enumerate}

(Extra Credit: 5 pts)Try the above smoothing with your own image pair!
Take 2 images with only(or mostly) a horizontal shift, and see the
result by editing the image paths and running the code. If you get good
results, explain why your image pair is ``easy''. If you get bad
results, explain why your pair is ``hard''. These results go in the
extra credit slides.



\end{document}
